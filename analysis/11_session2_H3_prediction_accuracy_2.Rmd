---
title: "Test of H3: There is additional predictive value in modelling rate of forgetting at the level of the individual learner and/or item relative to modelling rate of forgetting at the domain level"
author: "Maarten van der Velde"
date: "Last updated: `r Sys.time()`"
output:
  html_notebook:
    smart: no
    toc: yes
    toc_float: yes
  html_document:
    df_print: paged
    toc: yes
    toc_float: yes
---

# Overview

This notebook contains the analysis of Hypothesis 3, as preregistered at https://osf.io/vwg6u/:

> The prediction accuracy, expressed as the root mean square error (RMSE) of the predicted rates of forgetting relative to the observed rates of forgetting for each learner/fact combination, will be higher (i.e., the RMSE will be lower) for the best performing combination(s) of learner and/or fact history than for a prediction at the domain level, in which the predicted value is equal to the grand mean rate of forgetting across all learners and facts.




# Setup

## Load packages
```{r}
library(BayesFactor)
library(dplyr)
library(ggplot2)
library(purrr)
library(readr)
library(stringr)
library(tidyr)
library(fst)

theme_set(theme_light(base_size = 14) +
  theme(strip.text = element_text(colour = "black")))

knitr::opts_chunk$set(fig.width=16, fig.height=16) 
```


## Load data
```{r}
final_alpha_lab_2 <- read.fst(file.path("..", "data", "processed", "lab", "session2", "session2_rl2_final_alpha_lab.fst"))
final_alpha_mturk_2 <- read.fst(file.path("..", "data", "processed", "mturk", "session2", "session2_rl2_final_alpha_mturk.fst"))

fix_condition_labels <- function(x) {
  rowwise(x) %>%
  mutate(condition = str_to_title(condition)) %>%
  mutate(condition = gsub("-", "\n", condition)) %>%
  mutate(condition = gsub("And", "and", condition)) %>%
  mutate(condition = gsub("Student", "Learner", condition)) %>%
  ungroup()
}

final_alpha_lab_2 <- fix_condition_labels(final_alpha_lab_2)
final_alpha_mturk_2 <- fix_condition_labels(final_alpha_mturk_2)

final_alpha_2 <- bind_rows(mutate(final_alpha_lab_2, dataset = "Lab"),
                         mutate(final_alpha_mturk_2, dataset = "MTurk"))
```



## Subset data
The preregistration specified 22 April 2019 as the cutoff date for data collection.
We reached the minimum of 25 participants per condition in the lab sample before this date, but not in the Mechanical Turk sample.
For that reason data collection on MTurk continued until there were at least 25 participants per condition (14 May 2019) and was stopped only then.
The analysis reported in the paper is based only on the data from before the cutoff date, but this notebook also reports the same analysis done on the full dataset. 

```{r}
subjects_cutoff <- read_csv(file.path("..", "data", "processed", "subjects_before_cutoff.csv"))

final_alpha_2_full <- final_alpha_2 

final_alpha_2_cutoff <- final_alpha_2 %>%
  right_join(subjects_cutoff, by = "subject")
```

# Predicted vs. observed

Compare the predicted rate of forgetting, used as the initial estimate, and the observed rate of forgetting (i.e., the final estimate).
Only facts that were repeated at least 3 times are included.

```{r}
rmse <- function(a, b) {
  sqrt(mean((a - b)^2))
}

pred_acc_by_subj_cutoff <- final_alpha_2_cutoff %>%
  group_by(dataset, condition, subject) %>%
  summarise(correlation = cor(prediction, final_alpha),
            rmse = rmse(prediction, final_alpha)) %>%
  ungroup() %>%
  mutate(dataset = as.factor(dataset),
         condition = as.factor(condition))

pred_acc_by_subj_full <- final_alpha_2_full %>%
  group_by(dataset, condition, subject) %>%
  summarise(correlation = cor(prediction, final_alpha),
            rmse = rmse(prediction, final_alpha)) %>%
  ungroup() %>%
  mutate(dataset = as.factor(dataset),
         condition = as.factor(condition))

pred_acc_by_cond_cutoff <- pred_acc_by_subj_cutoff %>%
  group_by(dataset, condition) %>%
  summarise(correlation_mean = mean(correlation, na.rm = T),
            correlation_sd = sd(correlation, na.rm = T),
            rmse_mean = mean(rmse, na.rm = T),
            rmse_sd = sd(rmse, na.rm = T)) %>%
  mutate(condition = gsub("\n", " ", condition))


pred_acc_by_cond_full <- pred_acc_by_subj_full %>%
  group_by(dataset, condition) %>%
  summarise(correlation_mean = mean(correlation, na.rm = T),
            correlation_sd = sd(correlation, na.rm = T),
            rmse_mean = mean(rmse, na.rm = T),
            rmse_sd = sd(rmse, na.rm = T)) %>%
  mutate(condition = gsub("\n", " ", condition))

```

## Individualised vs. domain predictions
The preregistered test of H2 did not find sufficient evidence of the expected effect of condition on prediction accuracy.
An exploratory analysis of the effect of adaptation as a whole did indicate that the four adaptive conditions taken together outperformed the default condition in terms of prediction accuracy (RMSE).

If some adaptation is better than no adaptation, is it also the case that adaptation at the level of the individual fact and/or learner is better than adaptation at the level of the domain?

Since we found overall differences in RMSE between the populations, do two separate one-sided Bayesian t-tests comparing the three individualised conditions to the domain condition.

For both datasets, RMSE is not lower in the individualised conditions than in the domain condition:
```{r}
ttestBF(filter(pred_acc_by_subj_full, dataset == "Lab", condition %in% c("Fact\nand\nLearner", "Fact", "Learner"))$rmse,
        filter(pred_acc_by_subj_full, dataset == "Lab", condition == "Domain")$rmse,
        nullInterval=c(-Inf, 0))
ttestBF(filter(pred_acc_by_subj_full, dataset == "MTurk", condition %in% c("Fact\nand\nLearner", "Fact", "Learner"))$rmse,
        filter(pred_acc_by_subj_full, dataset == "MTurk", condition == "Domain")$rmse,
        nullInterval=c(-Inf, 0))
```


**Conclusion: there is no additional predictive value in modelling rate of forgetting at the level of the individual learner and/or fact over modelling it at the domain level.**

---

# Session information
```{r}
sessionInfo()
```
